各位同学，大家好，我们这节课来讲绘制过程，我们之前已经讲完了command，然后我们也讲完了pipeline，我们也讲完了 render pass，那么将这一切捏合在一起的过程就是绘制过程，那绘制过程来讲它到底分为哪些步骤呢？我们先大概浏览一下绘制的流程，首先我们应该获交换链的下一张图片，这里面会有一个接口，就是 acquire next image，那么通过一个 Vulkan 的接口，我们就能够拿到下张图片的索引，就是index。那么我们回忆一下为什么会有这种下一张片这一说呢？因为在交换链当中我们可以生成 n 张的。什么呀？ n 张的image。

然后我们还有 end frame buffer，对吧？那么本次绘制就需要从假设我们有三张图，那么我们从这三张中就要取出一张来，那么具体取出哪一张是由 Vulkan 的交换链系统来决定的，一般都是顺序，第零张先取出来绘制，然后送去显示，然后第一张，第二张这样子好，取出来之后我们需要构建渲染指令的提交信息，我们之前做了 command buffer，并且把一些关于渲染跟绑定的指令录制进去了，录制完毕之后我们就要用这个frame，用这个 command buffer 来构建一个submitinfo，就是提交信息。

这里面记录了很多的东西，包括说我用哪一个 command buffer 进行提交。然后我之间的依赖关系如何？包括一些信号量的东西我们都会去讲。好，那么构建完这个提交器之后，我们就要设置依赖的顺序。为什么叫设置依赖顺序呢？举个简单的例子，你只有这张图是不是渲染完毕之后才能够去显示呢？那么显示这件事跟你的渲染这件事它就构成了一个依赖，那么接下来就是上传提交信息给到 GPU 开始执行，那么这个渲染这边就提交完毕了，那这个提交它只不过是将相关的指令以及信息发送给了GPU，那么 GPU 收到信息就开始顺序执行。

按照什么顺序呢？按照一个隐含的顺序，按照 command buffer 里面你录制指令的这样一个隐含顺序去执行这些指令。那对于显示来讲，我们首先也构建显示引擎的提交信息，仍然是刚才所讲的那些东西，要的是 slots 里面的哪一张图片送去显示，一般情况下是不是这渲染了一帧？比如说它的 index 等于0，把第0帧，把第一个图片给渲染好了，那么这边就应该去显示第0个图片的内容，然后设置依赖顺序，还是像刚才一样，你渲染完了，我这才能够显示，然后就是上传提交信息给到显示引擎进行执行，就去显示了。

好，这个就是它大概的一个流程，其实看上去也比较简单。那么我们现在提出一个问题，目前我们有绘制与显示两个命令的提交，那么其中如何同步两个步骤呢？它有两个需要同步的地方，第一个保证先绘制完毕再提交，对吧？然后再显示。然后显示完毕才能够在这个图片上进行绘制新的东西，你不能这边画了一半，你就提交去显示了，对吧？你这边也不能说我显示到一半，你又要在上面画新的，那么我们的答案就是要通过信号量叫 semaphore 这个东西进行控制，我们可以让显示命令在渲染命令执行完毕之后再继续执行，也可以让渲染命令在显示完毕后继续执行。我们这边用了叫继续开启和继续执行这个说法，为什么叫继续？我们来慢慢的展开一下。

首先我们单独摘出来 Vulkan 里面的一段代码，我们看一看，首先是 acquire next image。那么这个函数是什么意思呢？我们大概溜一遍，首先有一个信号量被传进来了，那么在这里我们讲之前，先讲一讲这个信号量是什么东西？信号量有激发态跟非激发态两种，说白了大家可以认为有 0 和一两个状态就是一个标志位。好，我们就这么去理解它，那么这个函数调完之后，它就会传回一个什么呢？传回一个 image index，就是目前我可以绘制的下一张图片，应该是谁在我的 SUB chat 队列里面看一看，对吧？那么假设它把第一帧一张图片给返回来了，那么我接下来就要提交渲染信息，我要在第一张图片上进行绘制。

那么我这边就会做一个叫做 signal 的数组，那个信号量的数组，那这个信号量的数组里面装的就是 imageavailable signal，就是说这张图片已经可以去渲染了这么一个标志位，此时这个标志位它仍然是一个空，或者是0，或者说非激发态。

那么也就是说这个指令它即便是送入执行之后，那么系统一看，哎，你这个还没有被激发，还是0，那么我肯定就会阻挡住渲染的过程，那请问我到底哪个过程是需要去被阻挡的？这边会告诉我们， wait stages 就需要等待这个信号量被激发的这个阶段是哪个阶段呢？是 color attachment output bit，也就是说 fragment shader 输出颜色的时候，那个阶段就在这被阻挡住了。

那么接下来我们就把这个信息填写到这个 submit info 里面，就是提交信息里面。当然这个提交信息也会有其他的参数，比如说提交的具体是哪个 command buffer 也会在这填写好，那么我们看一下同步过程，梳理一下指令缓冲提交结构关联了一个什么呢？需要等待的信号，然后本指令缓冲需要在 wait stage 的地方停下来，就是在这个颜色输出这边停下来，为什么要在这停下来呢？那是因为那边还没有显示完毕，你肯定不能够向上去输出颜色，那么在这边等待 signal 的激发，那么在显示完毕之后，那么显示引擎就会将这个 image available signal 给它置为激发态，因为在这个函数里面，我们已经把它与当前这张图片给绑定了，绑定之后，如果这个第一号图片它可以被用来绘制了，也就是说它显示完毕了，那这家伙就被激发了。

激发之后，那么这个 stage 就也进行继续进行执行了，所以我们之前说叫继续执行，有一个同步的概念在里面，因为你这边不管说你这个信号量激不激发，对吧？我只要不去向你这个图像输出最后的绘制，那么前面的 MVP 矩阵变换，我texshader、geometryshader、 fragmentshader 都可以执行，只不过到最后 fragmentshader 执行完毕之后的像素它输出不出去。

好，那么我们看一下显示等待渲染它是有什么依赖的？仍然需要一个 signal semaphore，对吧？那么它等于 render finished，我们又创建了一个新的信号量，它是说我等待的事件是 Render finish，这个事件渲染完毕，那么把它也是放到 submitinfo 里。然后这边我们在 present info 就是显示信息里面把这个信号量给它加上。ok，这边有一个口误是这样，就是这边的 submit info 仍然是渲染指令，也就是说跟上面这个 submit info 是一个东西。

那么重新解释一下这个 render finished semaphore 是干的，是说我这本次提交不是提交了一个 command buffer，对吧？那么这个 command buffer 它执行完毕之后，那么它需要点亮或者说击哪一个semaphore，那么渲染完毕之后就激发这个 render finished semaphore，那对于显示来讲的话，我就得等待你这个 signal 的这个 render finished semaphore，就是这个 signal 的semaphores，对吧？等待这家伙的话，那么他这边渲染完毕，一激发我这边的显示是不是就可以执行了？是这个道理。

好，我们看一下，梳理下过程，指定缓冲提交结构关联一个需要的sample，就是这个 render finish sample，本指令缓冲需要在指令集合整体执行完毕之后，就是 command buffer，执行完毕之后会激发此sample，然后激发出来之后依赖本信号的操作才可以执行，比如说这显示操作就是可以执行了。

好，那么我们详细解释一下这个过程啊。首先我们创建了一个 image available sample，然后我们把它送到显示引擎，就是刚才那个 acquire next image。然后显示引擎将这个 image 与 index 进行绑定，假设是一第一张图片，此时交换链的第 image index 张图片已经与这个信号量绑定了，然后绑定之后，这边我们就假设并提交完毕了绘制的指令。

我们现在假设的情况是什么呢？就是刚才那个，那那几个函数，那几个命令都已经执行完毕了，显示命令以及渲染命令都已经提交到 GPU 了，我们现在看一看在 GPU 上和显示引擎上到底发生了什么。对于渲染来讲，它就开始对 1 号图所对应的这个部分的东西开始渲染，但实际上并没有真正输出到颜色，它可能现在正在走 Vertex shader 或者是 fragment shader 等等。它走到 fragment 阶段，即将要输出的时候就卡在这了。为什么呀？因为它依赖这个信号量。那么假设现在这个显示引擎正在读取这张图片上的东西，还没有显示完，那么它就一直要卡着。好，现在显示引擎说，哎，我读取完整张图片了，我已经显示完，那么我就会告诉你可以激发这个信号量了。信号量，那么这个渲染过程就会持续进行，就会向这个 1 号图上直接输出源。

同样我们还有一个过程是显示过程，是说我要把这个 1 号图显示到屏幕上，那么大家注意这个地方，我们对于它这两个指令的提交，这两个 submit info 的提交是顺序提交并行执行的，那也就是说这个渲染的过程和这个准备去显示 1 号图的过程是并行的。那并行的话，这两个指令你别看在编程层面上来讲， CPU 上是先把这个指令发出去，再把这个三维的指令发出去，那么但其实它同时发到 GPU 之后同时执行，也就是说这边卡在这等这个信号量，那这边它卡在哪了呢？它卡在了这个渲染输出的要去激发的这个 render finish 的信号量上了，也就是说这个渲染引擎它在这边同时在什么呢？在等待这个渲染，它去激发一个信号量，就是 render finish 的semaphore，OK，那么它激发了这个之后就可以真正的读取显示了，这个渲染引擎就可以读取这个刚刚渲染出来的这张热乎乎的图片就可以读了。

好，它整个过程就是这样的，所以说整个过程的核心思想就在于 Semaphore 其实控制了。大的 stage 之间的一个同步。好，我们考察一下细节的问题，我们还记得吗？从渲染获取到的图片，它是一个什么样的layout？它是一个 imagepresent k java layout。但是我们渲染是需要 attachment output optimal 这么一个优化的layout，那换句话说，渲染好的图像肯定就是这么 output optimal 的一个layout，但是显示需要的是 imagepresent 这么一个layout，所以只使用信号量的控制它仍然是不够的。

那么其实这方面的知识我们在之前讲 render pass 的时候就讲过了，解答一下。在 render pass 的 SUBPASS 当中，我们已经通过 attachment description 以及 attachment reference 对 image 的格式做出了归一。所以说这个 seven flow 它只是控制了一个大的过程，各种 stage 之间的同步。比如说 color 输出的 stage vs 输入的 stage 等等，那么在除了这个 pipeline stage 层面的控制之外，它中间在进出 SUB pass 以及进出整个 render pass 的时候，它会根据这个 attachment description 和 attachment reference 对于格式的要求在它的中间插入相应的 barrier 自动格式转换。

这个如果忘记的同学，我们可以回头去看一看我们讲 render pass 的时候，最终的那个总结的那堂课，那么插入这个格式自动转换，其实就是一个内存的屏障，在这个输出到渲染，在输出到这个显示引擎之前，就会将图片的格式从这个 RGB 改为present。这个格式，那么这个转换是由谁来控制？它的这个依赖的就是由这个自动插入的barrier，那 barrier 我们后面还会去讲它。OK，那么这节课我们就讲到这里。

